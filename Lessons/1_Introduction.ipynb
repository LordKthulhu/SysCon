{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9432cf3b-27ed-4b3b-b929-86908c240e61",
   "metadata": {},
   "source": [
    "# Introduction to Newton's (Newton-Raphson) method\n",
    "\n",
    "*[Written by: Maxime Pierre, 2023]* \\\n",
    "Newton's method is one of the most common methods for solving nonlinear equations numerically. \\\n",
    "In this notebook, we will introduce the method and implement it to solve a simple one-dimensional example. \\\n",
    "\\\n",
    "For instance, let us consider the following nonlinear equation:\n",
    "$$ x\\in\\mathbb{R} : \\cos(x)=x^3 $$\n",
    "Finding the solution to this equation amounts to finding the zero of the following function:\n",
    "$$ f : x \\rightarrow \\cos(x)-x^3 $$\n",
    "Let us plot this function first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e1cdfe-afc7-48cb-a04a-d2f50af76412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def f(x):\n",
    "    return ### Exercise: write function f ###\n",
    "\n",
    "# Plot bounds\n",
    "x_inf = 0\n",
    "x_sup = 1.2\n",
    "\n",
    "X = np.linspace(x_inf, x_sup, 100)\n",
    "\n",
    "fig = plt.figure()\n",
    "gc = fig.gca()\n",
    "gc.plot(X, f(X), label=r\"$\\cos(x)-x^3$\")\n",
    "gc.legend()\n",
    "gc.set_xlabel(r\"x\")\n",
    "gc.set_ylabel(r\"y\")\n",
    "gc.axhline(0, color='black', linewidth=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747c7f76-6d48-4c3e-98d9-04120629f80b",
   "metadata": {},
   "source": [
    "As we can see, $f$ has a zero for a value of $x$ close to $0.9$, but we want to get a precise approximation of our solution. \\\n",
    "The idea behind Newton's method is to use the derivative of $f$ to get a sequence of values $x_0, x_1, \\dots, x_n$ which converges towards the solution $\\hat{x}$ such that $f(\\hat{x})=0$. \\\n",
    "$f$ is easily derivable and we have:\n",
    "$$ f': x \\rightarrow -\\sin(x)-3x^2. $$\n",
    "We have to start with an initial guess of the solution: let us say $x_0=0.5$. We will draw the tangent line to the graph of $f$ at $f(x_0)$, which has equation:\n",
    "$$ t_0 : x \\rightarrow f(x_0) + f'(x_0)(x-x_0). $$\n",
    "This tangent line intersects with the $x$-axis at $x_1$, such that:\n",
    "$$ f(x_0) + f'(x_0)(x_1-x_0) = 0, $$\n",
    "which gives us:\n",
    "$$ x_1 = x_0 - \\frac{f(x_0)}{f'(x_0)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b13d16-def9-4ab9-80f7-796f72f9145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0 = 0.5\n",
    "\n",
    "def f_prime(x):\n",
    "    return ### Exercise: write the derivative of f ###\n",
    "\n",
    "x_1 = ### Exercise: calculate x_1 ###\n",
    "\n",
    "gc.plot([x_inf, x_sup], [f(x_0)+f_prime(x_0)*(x_inf-x_0), f(x_0)+f_prime(x_0)*(x_sup-x_0)], 'k--') # t_0 tangent\n",
    "gc.scatter([x_0, x_1], [f(x_0), 0], c='r')\n",
    "gc.plot([x_0, x_0], [0, f(x_0)], 'r--') # x_0 projection\n",
    "gc.annotate( r\"$x_0$\", (x_0, -0.1), c='r' )\n",
    "gc.annotate( r\"$x_1$\", (x_1, 0.1), c='r' )\n",
    "\n",
    "print(\"Value of x_1:\", x_1, \"\\n\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7509a7-1249-4b70-81f9-9444bcb6bbd6",
   "metadata": {},
   "source": [
    "The first iteration gives us a new point $x_1$ closer to $\\hat{x}$. The idea now is to iterate to get closer and closer to the solution. \\\n",
    "The next value $x_2$ is determined from $x_1$ in the same way $x_1$ is determined from $x_0$:\n",
    "$$ x_2 = x_1 - \\frac{f(x_1)}{f'(x_1)}. $$\n",
    "\n",
    "Let us draw the new tangent $t_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aae1ae2-5d65-49bf-bdbf-d38e07354242",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2 = ### Exercise: calculate x_2 ###\n",
    "\n",
    "gc.plot([x_inf, x_sup], [f(x_0)+f_prime(x_0)*(x_inf-x_0), f(x_0)+f_prime(x_0)*(x_sup-x_0)], 'y--')\n",
    "gc.plot([x_inf, x_sup], [f(x_1)+f_prime(x_1)*(x_inf-x_1), f(x_1)+f_prime(x_1)*(x_sup-x_1)], 'k--') # t_1 tangent\n",
    "gc.scatter([x_1,x_2], [f(x_1), 0], c='r')\n",
    "gc.plot([x_1, x_1], [0, f(x_1)], 'r--') # x_1 projection\n",
    "gc.annotate( r\"$x_2$\", (x_2, 0.1), c='r' )\n",
    "gc.set_ylim(-1.5, 1.5)\n",
    "\n",
    "print(\"Value of x_2:\", x_2, \"\\n\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e898927-e8f8-4856-98d7-27f2d1afe217",
   "metadata": {},
   "source": [
    "We are closing in on the solution. Now, we will automatically iterate until we reach a certain precision. \\\n",
    "Given a current value $x_n$, $x_{n+1}$ is still determined in the same way:\n",
    "$$ x_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)}. $$\n",
    "\n",
    "We also need a stopping condition. With $\\varepsilon > 0$ an arbitrary precision, we will iterate **while** $\\lvert f(x_n) \\rvert > \\varepsilon$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafb0a62-5f74-465a-beb5-26052e593026",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-12 # Precision\n",
    "\n",
    "def NewtonMethod(function, derivative, initial_guess, tolerance, max_iteration = 20):\n",
    "    x_n = initial_guess\n",
    "    x = [initial_guess] # To store subsequent iterations\n",
    "    iteration = 0\n",
    "    while ### Exercise: tolerance criterion here ### and iteration < max_iteration:\n",
    "        \n",
    "        ### Exercise: update x_n value ###\n",
    "    \n",
    "        x.append(x_n)\n",
    "        iteration += 1\n",
    "        print(\"Iteration {}: x_{} = {}, f(x_{}) = {}\".format(iteration, iteration, x_n, iteration, function(x_n)))\n",
    "    if abs(f(x_n)) > eps: # Not converged\n",
    "        print(\"Did not converge after {} iterations.\".format(iteration))\n",
    "    else: # Converged\n",
    "        print(\"Converged in {} iterations.\".format(iteration))\n",
    "    return x\n",
    "\n",
    "result = NewtonMethod(f, f_prime, x_0, eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed0f287-41bb-4ec1-87e9-0e11ae73da1a",
   "metadata": {},
   "source": [
    "You can now try the algorithm on other functions if you'd like!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce10282-09c3-4ebb-b45f-28945dda1d8f",
   "metadata": {},
   "source": [
    "# Bonus: Sensitivity to initial guess and non-convergence\n",
    "\n",
    "Newton's method is not guaranteed to always converge towards the solution (which is why we introduced a maximum number of iterations in our `NewtonMethod` function!). In particular, the choice of the initial guess $x_0$ can have a huge influence on the algorithm if the function is not regular enough. \\\n",
    "Let us illustrate that with an example. Consider the following function:\n",
    "$$ f : x \\rightarrow x^3-2x+2. $$\n",
    "Let us apply Newton's method with an initial guess of -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eeb57b-0c13-40bd-80cc-99d6ae63b89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x**3 - 2*x +2\n",
    "    \n",
    "def f_prime(x):\n",
    "    return 3*x**2 -2\n",
    "\n",
    "x_0 = -1\n",
    "eps = 1e-12\n",
    "\n",
    "X = np.linspace(-2,2,100)\n",
    "plt.figure()\n",
    "plt.plot(X, f(X), label=r\"$x^3-2x+2$\")\n",
    "plt.legend()\n",
    "plt.xlabel(r\"x\")\n",
    "plt.ylabel(r\"y\")\n",
    "plt.axhline(0, color='black', linewidth=.5)\n",
    "plt.show()\n",
    "\n",
    "result = NewtonMethod(f, f_prime, x_0, eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfe23cb-7d1b-4dec-8d1e-2edb545f52e3",
   "metadata": {},
   "source": [
    "The convergence is easy. Let us now try with an initial guess of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c881cea-cc46-43ac-9c97-bd6f81d5afe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0 = 0\n",
    "result = NewtonMethod(f, f_prime, x_0, eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3581c3-18aa-450d-a251-69a805e654ec",
   "metadata": {},
   "source": [
    "The method oscillates between 0 and 1, and is unable to find the zero of the function. Other guesses will lead to convergence at the cost of a significantly higher number of iterations. \\\n",
    "Let us try $x_0 = 0.7$: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f7764c-6004-4ea1-9700-40f8f1e936e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0 = 0.7\n",
    "result = NewtonMethod(f, f_prime, x_0, eps, max_iteration=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c027efa8-bf66-4ca9-925f-85a5a82ea6f1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
